systemctl start redisd
ps aux | grep redis
kill -9 8589
cp redis.conf /etc/redis/6379.conf


================================================================zookeeper====================================================================
dataDir=/root/zookeeper/zk1/data
dataLogDir=/root/zookeeper/zk1/dataLog
# the port at which the clients will connect
clientPort=2181
server.1=127.0.0.1:2888:3888
server.2=127.0.0.1:2889:3889
server.3=127.0.0.1:2890:3890


dataDir=/root/zookeeper/zk2/data
dataLogDir=/root/zookeeper/zk2/dataLog
# the port at which the clients will connect
clientPort=2182
server.1=127.0.0.1:2888:3888
server.2=127.0.0.1:2889:3889
server.3=127.0.0.1:2890:3890


dataDir=/root/zookeeper/zk3/data
dataLogDir=/root/zookeeper/zk3/dataLog
# the port at which the clients will connect
clientPort=2183
server.1=127.0.0.1:2888:3888
server.2=127.0.0.1:2889:3889
server.3=127.0.0.1:2890:3890

客户端sh zkCli.sh -server 127.0.0.1:2181
idea插件：zookeeper

================================================================zookeeper====================================================================

================================================================JDK==========================================================================

wget --no-check-certificate --no-cookies --header "Cookie: oraclelicense=accept-securebackup-cookie" http://download.oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.tar.gz

JAVA_HOME=/usr/java/jdk1.8.0_131
PATH=$JAVA_HOME/bin:$PATH
CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar 
export JAVA_HOME PATH CLASSPATH 

重新加载配置文件：source /etc/profile

================================================================JDK==========================================================================


================================================================Kafka==========================================================================
1.下载：wget http://mirror.bit.edu.cn/apache/kafka/2.3.0/kafka_2.11-2.3.0.tgz 
2.解压：tar -zxvf kafka_2.11-2.3.0.tgz
3.修改zk配置：vim config/server.properties
4.启动：sh kafka-server-start.sh -daemon ../config/server.properties
	sh kafka-server-start.sh -daemon ../config/server-1.properties
	sh kafka-server-start.sh -daemon ../config/server-2.properties
 daemon代表后台进程
  停止 sh kafka-server-stop.sh ../config/server.properties
  发送：sh bin/kafka-console-producer.sh --broker-list 106.12.129.197:9092 --topic my-replicated-topic
  消费：sh bin/kafka-console-consumer.sh --bootstrap-server 106.12.129.197:9092 --from-beginning --topic my-replicated-topic
5.接下来的操作命令可以查看官网：http://kafka.apache.org/documentation/#quickstart
6.集群：
	多台机器解压
	修改配置文件：zk、broker.id
		      listeners=PLAINTEXT://:9092
		      advertised.listeners=PLAINTEXT://106.12.129.197:9092
7.生产环境需要调优的参数：
    发送端：
	batch.size(16kb):producer对于同一个分区来说，会按照设置的大小进行统一收集进行批量发送
	linger.ms(0)：delay之后再批量发送到broker，这2个参数协同工作，只要满足一个就执行(Nagle算法)，但是linger.ms默认为0，则batch.size会不生效
	max.request.size(1M)

    消费端：
	GroupID，同一个Group只能消费一次，组内竞争。kafka都会持久化到磁盘上，所有你换一个消费组，则可以再次消费
	AUTO_OFFSET_RESET_CONFIG：
		如果设置为earliest：对于新的GroupId来说，对于新的则会从最早的消息开始消费，即重置offset;
		如果设置为lastest：新的消费者将会从其他消费者最后消费的offset 处开始消费 Topic 下的消息
		如果设置为none：新的消费者加入以后，由于之前不存在offset，则会直接抛出异常
	ENABLE_AUTO_COMMIT_CONFIG和AUTO_COMMIT_INTERVAL_MS_CONFIG配合使用

================================================================Kafka==========================================================================

================================================================redis==========================================================================
单机-读写分离，ssd，活动历史，分区分库分表，集群分布式微服务
为什么要用缓存：
	提升查询性能，减轻数据库压力，降低存储成本(缓存访问速度快，减少机器成本)。因为内存的访问性能是最好的，但是所有数据都放内存是不现实的，内存资源昂贵且有限，根据28理论，20%的时间都在访问80的热点数据，
  所有我们可以引入缓存组件去把热点数据放到缓存里面，可以提升整个系统的一个承载能力，这时我们就可以在应用和数据库中间加一个缓存层，比如redis。
缓存组件：不是单一组件，会用到多级缓存，比如内存缓存组件和分布式缓存组件结合
写入缓存方式：
	写入数据库后，插入缓存
	查询数据库，写入缓存
	定时刷新
缓存分类：
	应用类缓存，例如HashMap等
	组件缓存，例如redis，mamabcache
redis存储结构：redis实例--db(默认16个db空间)--key--value，redis比mamabcache提供更丰富的结构，string、list、hash、set、sorted-set
redis默认支持哪几种结构：字符串、整数、浮点，对整数类型可以调用INCT实现原子递增，比较多为计数器
redis内部基于的数据结构：sds、int
过期时间：expire
	消极(passive way)
	     在访问时发现如果已经失效，就删除它
	积极:周期的从设置了过期时间的key中选择一部分删除，redi每秒会进行10次操作，流程如下：
	     随机测试20个带有timeout的key
	     如果超过25%的key被删除，则重复执行整个流程
持久化：
	RDB：fork一个子进程，将数据写入临时文件，等到持久化结束，用次临时文件替换上次的持久化文件，整个过程主进程没有IO操作，性能极高，但是最后一次的持久化文件可能会丢失。
	     dump.rdb文件
	     save：阻塞
	     bgsave：后台异步快照，不影响客户端请求
	AOF：Appeng Only File，除了内存，会追加写入磁盘，会稍微降低性能
内存回收：redis提供了多种内存回收的策略，当内存不足时，为了保证程序的运行，这时不得不淘汰内存中的一些对象，那么淘汰哪些对象呢？
	LRU：最近最少使用
	maxmemory-policy:
	noeviction,默认，当内存使用达到阈值的时候，所有引起申请内存的命令会报错
	allkeys-lru:从数据集(server.db[i].dict)中挑选最近最少使用的数据淘汰,适合场景：如果我们的应用对缓存的访问都是相对热点数据，那么可以选择这个策略
	allkeys-random 随机移除某个key,适合场景：如果我们的应用对于缓存key的访问概率相等，则可以使用这个策略
	volatile-random：从已设置过期时间的数据集(server.db[i].expires)中任意选择数据淘汰
	volatile-lru：从已设置过期时间的数据集(server.db[i].expires)中挑选最近最少使用的数据淘汰
	volatile-ttl：从已设置过期时间的数据集(server.db[i].expires)中挑选将要过期的数据淘汰,适合场景：这种策略使得我们可以向redis提示哪些key更适合被淘汰，我们可以自己控制
单线程为什么性能很高：
	redis的瓶颈不在于cpu，而在于内存和网络
	完全基于内存
	单线程不用cpu上下文切换，不用考虑锁的问题
	I/O多路复用(也叫异步阻塞I/O)，虽然是单线程，但是不会阻塞用户请求，不会等上一个请求完毕才会响应
================================================================redis==========================================================================


